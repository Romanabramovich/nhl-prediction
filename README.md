# NHL Win Prediction Model

A production-ready machine learning system that predicts NHL game outcomes using XGBoost with performance tracking.

## ğŸ¯ Overview

This project implements an end-to-end ML pipeline that:
- Ingests daily NHL data (games, standings, team stats) via NHL API
- Engineers comprehensive features from team performance metrics
- Trains XGBoost models to predict game outcomes
- Generates daily predictions for upcoming games
- Tracks and evaluates prediction accuracy over time

**Key Metrics:**
- Features: 120+ engineered features per game
- Historical Data: Multiple seasons of NHL games
- Performance: Tracked via comprehensive evaluation metrics

## ğŸ—ï¸ Architecture

```mermaid
flowchart TD
    A[NHL API<br/>api-web.nhle.com] --> B[ETL Pipeline<br/>â€¢ Schedule Ingestion<br/>â€¢ Standings/Stats<br/>â€¢ Labels]
    B --> C[PostgreSQL Database<br/>â€¢ games<br/>â€¢ team_stats<br/>â€¢ labels<br/>â€¢ feature_snapshots<br/>â€¢ predictions]
    C --> D[Feature Engineering<br/>â€¢ Rolling form<br/>â€¢ Rest/B2B<br/>â€¢ Home/Road splits<br/>â€¢ Standings position<br/>â€¢ Streaks<br/>â€¢ Goal differentials]
    D --> E[XGBoost Model<br/>â€¢ Hyperparameter tuning<br/>â€¢ Early stopping<br/>â€¢ Calibration]
    E --> F[Predictions & Evaluation<br/>â€¢ Performance tracking<br/>â€¢ Model evaluation]
```

## ğŸ“ Project Structure

```
nhl-prediction/
â”œâ”€â”€ ingest/                   # Data ingestion
â”‚   â”œâ”€â”€ clients/             
â”‚   â”‚   â””â”€â”€ nhl.py           # NHL API client with caching
â”‚   â””â”€â”€ loaders/             
â”‚       â”œâ”€â”€ schedule.py      # Game schedule loader
â”‚       â”œâ”€â”€ standings.py     # Team standings/stats loader
â”‚       â”œâ”€â”€ labels.py        # Game results loader
â”‚       â”œâ”€â”€ teams.py         # Team metadata loader
â”‚       â””â”€â”€ rosters.py       # Player roster loader
â”œâ”€â”€ features/                 # Feature engineering
â”‚   â”œâ”€â”€ build_snapshot.py    # Build feature snapshots
â”‚   â”œâ”€â”€ extract_features.py  # Extract features from snapshots
â”‚   â””â”€â”€ build_dataset.py     # Create train/val datasets
â”œâ”€â”€ models/                   # ML models
â”‚   â”œâ”€â”€ xgboost_model.py     # XGBoost training
â”‚   â”œâ”€â”€ inference.py         # Production inference
â”‚   â”œâ”€â”€ evaluate.py          # Model evaluation
â”‚   â”œâ”€â”€ evaluate_predictions.py  # Prediction tracking
â”‚   â”œâ”€â”€ hyperparameter_tuning.py # Hyperparameter optimization
â”‚   â”œâ”€â”€ baseline.py          # Baseline models
â”‚   â””â”€â”€ best_params.json     # Tuned hyperparameters
â”œâ”€â”€ database.py               # Database connection
â”œâ”€â”€ schema.sql                # Database schema
â”œâ”€â”€ backfill.py               # Historical data backfill
â””â”€â”€ docker-compose.yaml       # PostgreSQL setup
```

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.11+
- PostgreSQL 15+
- Docker (optional, for database)

### 2. Installation

```bash
# Clone repository
git clone <your-repo-url>
cd nhl-prediction

# Install dependencies
pip install -r requirements.txt

# Start PostgreSQL (using Docker)
docker-compose up -d

# Create database schema
psql -h localhost -U nhl_user -d nhl_prediction -f schema.sql
```

### 3. Configuration

Create a `.env` file with your database URL:

```bash
# .env
DB_URL=postgresql://nhl_user:nhl_password@localhost:5432/nhl_prediction
```

### 4. Initial Data Backfill

```bash
# Backfill 2024 season (adjust as needed)
python backfill.py --season 2024
```

This will:
- Fetch all games for the season
- Ingest daily standings/team stats
- Build feature snapshots for each game
- Collect labels for completed games

### 5. Create Modeling Datasets

```bash
python recreate_modeling_tables.py
```

Creates `modeling_train` and `modeling_val` tables for model training.

### 6. Train Model

```bash
# Train with default parameters
python models/xgboost_model.py

# Or tune hyperparameters first (recommended)
python models/hyperparameter_tuning.py
```

### 7. Generate Predictions

```bash
# Generate predictions for upcoming games
python models/inference.py
```

## ğŸ“Š Features

The model uses **120+ engineered features** including:

### 1. Rest & Scheduling (5 features)
- Days of rest for each team
- Back-to-back game indicators
- Rest differential

### 2. Rolling Form (20 features)
- Last 10 games: wins, losses, points
- Goals for/against
- Goal differential
- Regulation wins

### 3. Current Standings (12 features)
- League, conference, division rankings
- Home/road specific rankings

### 4. Situational Performance (32 features)
- Home record (wins, losses, goals, etc.)
- Road record
- Goal differentials by location

### 5. Streaks (2 features)
- Current win/loss streak
- Streak type and length

### 6. Season Aggregates (8 features)
- Total points, win percentage
- Goal differential percentage

## ğŸ“ˆ Model Performance

The XGBoost model is evaluated using:

- **Accuracy**: Percentage of correct predictions
- **Log Loss**: Probabilistic prediction quality
- **AUC-ROC**: Discrimination ability
- **Calibration**: Confidence vs actual accuracy
- **Baseline Comparison**: vs. always-home, random, etc.

**Track Performance:**
```bash
# Evaluate last 30 days
python models/evaluate_predictions.py

# Show detailed report
python models/evaluate_predictions.py --days 30 --top-n 20
```

## ğŸ—„ï¸ Database Schema

Key tables:

- `games` - Game schedule and metadata
- `teams` - Team information
- `team_stats` - Daily team statistics/standings
- `labels` - Game outcomes (training labels)
- `feature_snapshots` - Pre-computed features (as JSONB)
- `predictions` - Model predictions (for tracking)

See `schema.sql` for complete schema.

## ğŸ”§ Advanced Usage

### Hyperparameter Tuning

```bash
python models/hyperparameter_tuning.py
```

Saves best parameters to `models/best_params.json`.

## ğŸ§ª Development

### Running Tests

```bash
# Test database connection
python database.py

# Test API client
python ingest/clients/nhl.py

# Test feature extraction
python features/extract_features.py
```

### Local Development

1. Use local PostgreSQL or Docker
2. Set `DB_URL` in `.env`
3. Run `backfill.py` for historical data
4. Develop and test changes locally

## ğŸ“ Data Pipeline Details

### ETL Process

1. **Schedule Loader** (`ingest/loaders/schedule.py`)
   - Fetches games from NHL API
   - Updates game status (scheduled, live, final)
   - Handles preseason, regular, postseason

2. **Standings Loader** (`ingest/loaders/standings.py`)
   - Daily team statistics
   - Home/road/last-10 splits
   - Rankings across league/conference/division

3. **Labels Loader** (`ingest/loaders/labels.py`)
   - Final scores for completed games
   - Binary home_win target variable

4. **Feature Builder** (`features/build_snapshot.py`)
   - Point-in-time features (as of game day)
   - Prevents data leakage
   - Stores as JSONB for flexibility

